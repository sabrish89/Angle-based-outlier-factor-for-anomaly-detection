{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbs\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import multiprocessing as mp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from math import log\n",
    "def calculate_weight(pivot, n_1, n_2):\n",
    "    '''Calculates the weighing factor in numerator and denominator\n",
    "    This is              1\n",
    "                  ---------------\n",
    "                  ||AB|| * ||AC||\n",
    "    '''\n",
    "    if type(pivot) != np.ndarray:\n",
    "        pivot = np.asarray(pivot)\n",
    "    if type(n_1) != np.ndarray:\n",
    "        n_1 = np.asarray(n_1)\n",
    "    if type(n_2) != np.ndarray:\n",
    "        n_2 = np.asarray(n_2)\n",
    "    diff_AB = np.subtract(n_1,pivot)\n",
    "    diff_BC = np.subtract(n_2,pivot)\n",
    "    return 1.0/(np.linalg.norm(diff_AB)*np.linalg.norm(diff_BC))\n",
    "\n",
    "def calculate_angle(pivot, n_1, n_2):\n",
    "    '''Calculates the angular component in the numerator\n",
    "    This is           <AB,AC>\n",
    "                -------------------\n",
    "                ||AB||^2 * ||AC||^2\n",
    "    '''\n",
    "    if type(pivot) != np.ndarray:\n",
    "        pivot = np.asarray(pivot)\n",
    "    if type(n_1) != np.ndarray:\n",
    "        n_1 = np.asarray(n_1)\n",
    "    if type(n_2) != np.ndarray:\n",
    "        n_2 = np.asarray(n_2)\n",
    "    diff_AB = np.subtract(n_1,pivot)\n",
    "    diff_AC = np.subtract(n_2,pivot)\n",
    "    #dot product is commutative\n",
    "    if np.linalg.norm(diff_AB)**2 == 0:\n",
    "        print(diff_AB)\n",
    "    if np.linalg.norm(diff_AC)**2 == 0:\n",
    "        print(diff_AC)\n",
    "    return np.dot(diff_AB,diff_AC)/(np.linalg.norm(diff_AB)**2 * np.linalg.norm(diff_AC)**2)\n",
    "\n",
    "def perform_selection(X,k):\n",
    "    '''Variable selection\n",
    "       Selects the k most explanatory variables\n",
    "    '''\n",
    "    return X[:,np.argpartition(np.var(X,axis=0),-k)[-k:]]\n",
    "    \n",
    "def abof(D, normalize = False, selective = False, entropy = False, precision = 3):\n",
    "    '''Full ABOF algorithm.\n",
    "       Returns: the i/p dataset with an additional ABOF factor column\n",
    "       Complexity: O(n^3) - implement FAST-ABOF O(n*k^2), LB-ABOF O(n*k^2 + 2n) at cost of accuracy\n",
    "       Options: normalize - helps to view data better, normalized with max - default:False\n",
    "                selective - chooses only the top 25% of the columns with highest information/variance - default:False\n",
    "                entropy   - returns shannon entropy of dataset - default:False\n",
    "                precision - precision of normalization - default:3\n",
    "    '''\n",
    "    #Initialize the ABV array\n",
    "    sigma_theta = []\n",
    "    \n",
    "    #Examine the dataset\n",
    "    if type(D) != np.ndarray:\n",
    "        D = np.asarray(D)\n",
    "    \n",
    "    #Select only half the (important) variables\n",
    "    if selective == True:\n",
    "        D = perform_selection(D,round(D.shape[1]*0.25))\n",
    "    \n",
    "    #Iterate over points\n",
    "    for i in range(len(D)):\n",
    "        pivot = D[i]\n",
    "        subset_D_diff_i = np.delete(D,i,0)\n",
    "        local_theta_n_0 = 0.0\n",
    "        local_theta_n_1 = 0.0\n",
    "        local_theta_d = 0.0\n",
    "        sys.stdout.write(\"\\rComputing datapoint %s...%d%%\" % (i+1,round((i+1)/(len(D))*100)))\n",
    "        sys.stdout.flush()\n",
    "        for j in range(len(subset_D_diff_i)):\n",
    "            for k in range(j+1, len(subset_D_diff_i)):\n",
    "                local_theta_n_0 += calculate_weight(D[i],subset_D_diff_i[j],subset_D_diff_i[k])*(calculate_angle(D[i],subset_D_diff_i[j],subset_D_diff_i[k])**2)\n",
    "                local_theta_n_1 += calculate_weight(D[i],subset_D_diff_i[j],subset_D_diff_i[k])*calculate_angle(D[i],subset_D_diff_i[j],subset_D_diff_i[k])\n",
    "                local_theta_d += calculate_weight(D[i],subset_D_diff_i[j],subset_D_diff_i[k])\n",
    "        sigma_theta.append((local_theta_n_0/local_theta_d) - (local_theta_n_1/local_theta_d)**2)\n",
    "    \n",
    "    #Calculate Shannon Entropy\n",
    "    if entropy == True:\n",
    "        entr = calc_shannon_ent(D)\n",
    "        #Stitch the ABV array to i/p matrix\n",
    "        D = np.hstack((D,np.vstack(sigma_theta)))\n",
    "        #Normalize\n",
    "        if normalize == True:\n",
    "            D = np.round(D/np.max(D),precision)\n",
    "        return D, entr\n",
    "    else:\n",
    "        #Stitch the ABV array to i/p matrix\n",
    "        D = np.hstack((D,np.vstack(sigma_theta)))\n",
    "        #Normalize\n",
    "        if normalize == True:\n",
    "            D = np.round(D/np.max(D),precision)\n",
    "        return D\n",
    "    \n",
    "\n",
    "def fast_abof(D,k=5, normalize=False):\n",
    "    '''FAST ABOF algorithm.\n",
    "       Complexity reduction at expense of accuracy; near quadratic complexity for lower values of k.\n",
    "       Scales well with larger dimensions and data size. See paper for comparisons with full ABOF.\n",
    "       Returns: the i/p dataset with an additional ABOF factor column\n",
    "       Complexity: O(n*k^2) where k <<< n ~ quadratic complexity\n",
    "    '''\n",
    "    #Initialize the ABV array\n",
    "    sigma_theta = []\n",
    "    \n",
    "    #Examine the dataset\n",
    "    if type(D) != np.ndarray:\n",
    "        D = np.asarray(D)\n",
    "    \n",
    "    #Get k nearest neighbors\n",
    "    neighbors = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(D).kneighbors(D)[1]\n",
    "    \n",
    "    #Iterate over points\n",
    "    for i in range(len(D)):\n",
    "        pivot = D[i]\n",
    "        local_theta_n_0 = 0.0\n",
    "        local_theta_n_1 = 0.0\n",
    "        local_theta_d = 0.0\n",
    "        sys.stdout.write(\"\\rComputing datapoint %s...%d%%\" % (i+1,round((i+1)/(len(D))*100)))\n",
    "        sys.stdout.flush()\n",
    "        local_N = neighbors[i][1:]\n",
    "        for j in range(len(local_N)):\n",
    "            for k in range(j+1,len(local_N)):\n",
    "                local_theta_n_0 += calculate_weight(D[i],D[local_N[j]],D[local_N[k]])*(calculate_angle(D[i],D[local_N[j]],D[local_N[k]])**2)\n",
    "                local_theta_n_1 += calculate_weight(D[i],D[local_N[j]],D[local_N[k]])*calculate_angle(D[i],D[local_N[j]],D[local_N[k]])\n",
    "                local_theta_d += calculate_weight(D[i],D[local_N[j]],D[local_N[k]])\n",
    "        if local_theta_d == 0:\n",
    "            print(\"Issue:\",local_N)\n",
    "            sigma_theta.append(0)\n",
    "        else:\n",
    "            sigma_theta.append((local_theta_n_0/local_theta_d) - (local_theta_n_1/local_theta_d)**2)\n",
    "            \n",
    "    #Stitch the ABV array to i/p matrix\n",
    "    D = np.hstack((D,np.vstack(sigma_theta)))\n",
    "    \n",
    "    #Normalize\n",
    "    if normalize == True:\n",
    "        D = np.round(D/np.max(D),3)\n",
    "    \n",
    "    return D\n",
    "\n",
    "def calc_shannon_ent(D):\n",
    "    '''Shannon's entropy for Dataset D given by p*log p\n",
    "                                                     2\n",
    "       Returns: entropy(D)\n",
    "       Complexity: d*log(n)\n",
    "    '''\n",
    "    numEntries = len(D)\n",
    "    labelCounts = {}\n",
    "    for featVec in D: #the the number of unique elements and their occurance\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2) #log base 2\n",
    "    return shannonEnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
